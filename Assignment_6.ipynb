{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Purpose \n",
    "The purpose of this assignment is to start performing machine learning classification using Python and the Scikit Learn module, using real world data.\n",
    "\n",
    "Skills:\n",
    "In order to complete this assignment you will need to:\n",
    "\n",
    "Import and manipulate the data into a workable form\n",
    "Utilize Scikit Learn functionalities to answer analytical questions\n",
    "Practice python fundamentals and best practices\n",
    "Knowledge:\n",
    "This assignment will help you gain the following:\n",
    "\n",
    "Utilize Scikit Learn functionalities to perform classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determine which of your models gives the best performance and write a brief paragraph explaining why. Cite various metrics to support your decision. If their is not a definitive best model, describe the pros and cons of your models. 10 extra credit points will be rewarded to each of the top 5 performing models in the course.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Over the past 30 years, the mortality rate of breast cancer has dropped nearly 44%, according to the ACS (American Cancer Society). Part of that reduction in lethality has been a significant increase in detection time, facilitated at least partially by machine learning. Use the built-in breast cancer dataset from Scikit Learn and build 3 different machine learning classification models. Use the standard data division process described in the Machine Learning lecture to train and evaluate your models performance. '''\n",
    "'''Determine which of your models gives the best performance and write a brief paragraph explaining why. Cite various metrics to support your decision. If their is not a definitive best model, describe the pros and cons of your models. 10 extra credit points will be rewarded to each of the top 5 performing models in the course.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yemer\\anaconda3\\envs\\scikit_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yemer\\anaconda3\\envs\\scikit_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yemer\\anaconda3\\envs\\scikit_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yemer\\anaconda3\\envs\\scikit_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yemer\\anaconda3\\envs\\scikit_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\yemer\\anaconda3\\envs\\scikit_env\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic regression accuracy: 0.9473684210526315\n",
      "logistic regression cross validation accuracy: [0.92982456 0.93859649 0.95614035 0.92982456 0.95575221]\n",
      "logistic regression cross validation mean accuracy: 0.9420276354603322\n",
      "SVC accuracy: 0.9473684210526315\n",
      "SVC cross validation accuracy:  [0.85087719 0.89473684 0.92982456 0.94736842 0.9380531 ]\n",
      "SVC cross validation mean accuracy:  0.9121720229777983\n",
      "Random Forest accuracy :  0.9649122807017544\n",
      "Random Forest cross validation accuracy :  [0.94736842 0.93859649 0.99122807 0.96491228 0.97345133]\n",
      "Decision Tree cross validation  mean accuracy :  0.9156031672100605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score\n",
    "\n",
    "load_breast_cancer = load_breast_cancer()\n",
    "x = load_breast_cancer.data\n",
    "y = load_breast_cancer.target\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state = 42)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "#logistic regression\n",
    "LogisticRegression = LogisticRegression()\n",
    "LogisticRegression.fit(x_train,y_train)\n",
    "l_pred = LogisticRegression.predict(x_test)\n",
    "l_cv  = cross_val_score(LogisticRegression, x, y, cv = skf , scoring='accuracy')\n",
    "\n",
    "print(\"logistic regression accuracy:\",accuracy_score(y_test,l_pred))\n",
    "print(\"logistic regression cross validation accuracy:\",l_cv)\n",
    "print(\"logistic regression cross validation mean accuracy:\",l_cv.mean())\n",
    "#Support Verctor Machine\n",
    "SVC = SVC()\n",
    "SVC.fit(x_train,y_train)\n",
    "s_pred = SVC.predict(x_test)\n",
    "s_cv = cross_val_score(SVC, x, y, cv = skf, scoring = 'accuracy')\n",
    "print(\"SVC accuracy:\",accuracy_score(y_test,s_pred))\n",
    "print(\"SVC cross validation accuracy: \", s_cv)\n",
    "print(\"SVC cross validation mean accuracy: \", s_cv.mean())\n",
    "\n",
    "#Random Forest Classifier \n",
    "RandomForestClassifier = RandomForestClassifier()\n",
    "RandomForestClassifier.fit(x_train,y_train)\n",
    "r_pred = RandomForestClassifier.predict(x_test)\n",
    "\n",
    "r_cv = cross_val_score(RandomForestClassifier, x, y, cv = skf, scoring = \"accuracy\")\n",
    "\n",
    "print(\"Random Forest accuracy : \", accuracy_score(y_test,r_pred))\n",
    "print(\"Random Forest cross validation accuracy : \",r_cv)\n",
    "print (\"Decision Tree cross validation  mean accuracy : \",d_cv.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explaining the Winner Model: \n",
    "\n",
    "Out of the four models I attempted to fit, I found that the Random Forest Classifier had the best performance. Using Stratified K-Fold cross-validation with 5 splits, I ensured that each fold maintained the same class distribution as the original dataset. This method allowed me to evaluate how the model performed across different parts of the dataset, providing a comprehensive assessment.\n",
    "\n",
    "The Random Forest Classifier consistently achieved the highest accuracy scores across all folds, outperforming models like SVC, Logistic Regression, and Decision Tree. The cross-validation method was particularly helpful because it gave a detailed comparison of the models' performance across multiple runs, rather than relying on a single accuracy score. The range of accuracy scores for the Random Forest model was higher than the other models, confirming that it was the superior classifier in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scikit_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
